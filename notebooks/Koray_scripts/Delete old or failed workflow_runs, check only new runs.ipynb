{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script looks at all files\n",
    "### 1) Checks deleted files for md5 related fields and clears them\n",
    "###                         for qc metric and changes status of qc metric object to deleted\n",
    "###                         clears the qc metric field\n",
    "###                         for workflows and deletes all of them\n",
    "### 2) Checks other files for workflows and deleted old workflows\n",
    "###                                     and deleted problematic ones (status or rev)\n",
    "### takes around 20 min\n",
    "\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "#env = 'data'\n",
    "my_key = get_key('koray_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at 2018-11-29 02:50:07.617051\n",
      "11241 files in the system\n"
     ]
    }
   ],
   "source": [
    "print('started at', datetime.utcnow())\n",
    "\n",
    "# what kind of files should be searched for worflow run inputs, use url compatible naming\n",
    "\n",
    "# accepted workflows\n",
    "# workflow name, accepted revision numbers (0 if none), accetable run time (hours)\n",
    "workflow_details = [\n",
    "                    ['md5', ['0'], 1],\n",
    "                    ['fastqc-0-11-4-1', ['0', '1'], 12],    \n",
    "                    ['bwa-mem 0.2.5', ['0'],50],\n",
    "                    ['pairsqc-single 0.2.5', ['0'],12],\n",
    "                    ['hi-c-processing-bam 0.2.5', ['0'],50],  \n",
    "                    ['hi-c-processing-pairs 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nore 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nonorm 0.2.5', ['0'],100],\n",
    "                    ['hi-c-processing-pairs-nore-nonorm 0.2.5', ['0'],100],\n",
    "                    ['repliseq-parta 0.2.5', ['0'],100],\n",
    "                    ['bedGraphToBigWig',['0'], 12]\n",
    "                   ]\n",
    "workflow_names = [i[0] for i in workflow_details]\n",
    "\n",
    "deleted_wfr_no = 0\n",
    "files_with_deleted_wfr = 0\n",
    "\n",
    "date_since = '2010-01-01'\n",
    "add_deleted = True\n",
    "\n",
    "file_url = \"\"\n",
    "if run_what == 'Proc':\n",
    "    file_url = '/search/?type=FileProcessed&limit=all&q=date_created%3A%3E%3D' + date_since\n",
    "    print(file_url)\n",
    "    files = ff_utils.search_metadata(file_url ,key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url ,key=my_key))\n",
    "    \n",
    "elif run_what == 'Fastq':\n",
    "    file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D' + date_since\n",
    "    files = ff_utils.search_metadata(file_url, key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url, key=my_key))\n",
    "    # grab these guys, because they accumulate losts of md5 runs\n",
    "    for a_test in ['4DNFIO67AFHV','4DNFIXH5OV2H', '4DNFI5RQBUKE']:\n",
    "        files.insert(0,ff_utils.get_metadata(a_test, key=my_key))\n",
    "\n",
    "elif run_what == 'Custom':\n",
    "    file_url = '/search/?type=FileProcessed&limit=all&status=deleted&q=date_created%3A%3E%3D' + date_since\n",
    "    files = ff_utils.search_metadata(file_url , key=my_key)\n",
    "    # add deleted\n",
    "    if add_deleted:\n",
    "        file_del_url = file_url + \"&status=deleted\"\n",
    "        files.extend(ff_utils.search_metadata(file_del_url ,key=my_key))\n",
    "        \n",
    "elif run_what == 'Custom_no_date':\n",
    "    file_url = '/search/?md5sum=No+value&status=released&status=released+to+project&status=uploaded&type=FileCalibration&type=FileFastq&type=FileReference&type=FileMicroscopy'\n",
    "    files = ff_utils.search_metadata(file_url, key=my_key)    \n",
    "    \n",
    "    \n",
    "print(len(files), 'files in the system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 files in the system\n",
      "Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\n",
      "md5 old style or dub b04f3933-4099-4dc9-9922-149eff1f2860 4DNFIBEEN92C\n",
      "md5 old style or dub 34e169ef-21a6-4e6a-86db-fd07cd76d17b 4DNFI4KZIPV7\n",
      "md5 old style or dub e8352a19-bb7b-4ea4-b573-f49bb5ceac8e 4DNFIW3788O9\n",
      "md5 old style or dub 4aea0762-7c22-4b36-b09b-8239054eae8a 4DNFI0NK4G14\n",
      "md5 old style or dub 5f951fd9-1b50-4dc7-81a4-01af94eb35ed 4DNFI0NK4G14\n",
      "md5 old style or dub 6287609d-6d25-452f-8a7c-f20bf3e4e933 4DNFI0NK4G14\n",
      "md5 old style or dub 7b4d230b-321d-4577-b01f-0428015026f5 4DNFI0NK4G14\n",
      "md5 old style or dub d5977093-ffea-4303-9687-8fcc43de113e 4DNFI3HVC1SE\n",
      "md5 old style or dub 50a7e335-a389-4944-93cf-7b392226f665 4DNFI3HVU20D\n",
      "md5 old style or dub 5ad4a84f-bf0a-434c-830c-d4821fd09761 4DNFI3HVU20D\n",
      "md5 old style or dub 9b8c14f8-20ba-4b4d-af89-150a34a0d98d 4DNFIMIV7AHJ\n",
      "md5 old style or dub bc3971ff-7a28-462a-a30d-75ef5b55b352 4DNFI9P2SCZ7\n",
      "md5 old style or dub 3f320894-15f0-41a5-bb12-b2fa55939620 4DNFI4FLO6VF\n",
      "md5 old style or dub d71f7583-e59e-456c-afb7-285711bd091d 4DNFI3UBJ3HZ\n",
      "md5 old style or dub d6434ccf-7b42-4c51-aa3d-8751e2e3ae68 4DNFIH57WWDH\n",
      "md5 old style or dub 3d0eda35-dad7-49a5-9b96-6c0ee5ddc52d 4DNFITENF6R5\n",
      "md5 old style or dub 68cc0309-98b7-4344-8b42-f5d8ded041e5 4DNFIUS321IU\n",
      "md5 old style or dub c33e7d69-62d0-4ce9-bacf-b535bfba07f9 4DNFIUS321IU\n",
      "md5 old style or dub 79e0b892-ade9-43af-8d2b-dd653ca54d73 4DNFI6YRVRKH\n",
      "md5 old style or dub 2c7ed996-62b3-43e3-affa-35b431c8780d 4DNFI6YRVRKH\n",
      "md5 old style or dub eb77a112-a705-4de3-b31c-30cb87aa9cbe 4DNFI823MBKE\n",
      "md5 old style or dub 6a3547fa-5eba-4110-bbc4-3eda50695808 4DNFI823MBKE\n",
      "md5 old style or dub 8b6f9129-268f-47b8-b931-97452a241d58 4DNFI823MBKE\n",
      "md5 old style or dub 6e15c57d-54b6-4fcf-9fb0-a14c067b67d6 4DNFI823MBKE\n",
      "md5 old style or dub 6521785c-82b5-46ce-8122-06c857872e3b 4DNFI823LSII\n",
      "md5 old style or dub cc03a01e-627a-4194-a9e2-088fee996617 4DNFI823LSII\n",
      "md5 old style or dub f6d3cf47-09b8-4553-91f4-9a759b5bb2fe 4DNFI823LSII\n",
      "md5 old style or dub 897b9325-730f-4e58-a7e7-3321fa454f1f 4DNFI823LSII\n",
      "md5 old style or dub 6e4e7a5a-9b89-4a7a-8e56-04893d2463c8 4DNFI823L812\n",
      "md5 old style or dub e524e32d-7b5a-4efb-a405-12752c5814d6 4DNFI823L812\n",
      "md5 old style or dub 4ca858fe-679a-463e-86ec-6c8c7444fd28 4DNFI823L812\n",
      "md5 old style or dub 77a8692a-9abd-4201-9d2a-70af6cf8e1db 4DNFI823L812\n",
      "md5 old style or dub 84bbb662-4f5a-4f0a-8513-a9dedbf044ca 4DNFI823L812\n",
      "md5 old style or dub 804a21e4-588c-4f3d-8e71-26e352849dda 4DNFI823L811\n",
      "md5 old style or dub 7b0262e7-0067-4880-b8a4-cd753e06d784 4DNFI823L811\n",
      "md5 old style or dub dfbe533d-0a25-4054-9595-2bc2ce1e8958 4DNFI823L811\n",
      "md5 old style or dub 275ffddd-3917-4c74-87d7-879ad2f8d4e0 4DNFI823L811\n",
      "md5 old style or dub 27d5652d-1977-4ca7-97c5-3bd3742c9a1e 4DNFI823L888\n",
      "md5 old style or dub d1b117b6-5a9d-43f7-989a-c48be47f4d64 4DNFI823L888\n",
      "md5 old style or dub 79ffa42f-2ac9-4a18-85f5-020d3dea7ccd 4DNFI823L888\n",
      "md5 old style or dub a5cf9f0f-6b4f-4a0a-9998-0b7e6cfce5c9 4DNFI823L888\n",
      "md5 old style or dub 13c9d5bc-2acc-4092-949a-5e32e6c58061 4DNFI823LSI8\n",
      "md5 old style or dub 0a6edaf4-51c4-4c0c-84f1-c48ae3856ad7 4DNFI823LSI8\n",
      "md5 old style or dub c1e014fc-7b1a-4038-9bce-7d32e8481986 4DNFI823LSI8\n",
      "md5 old style or dub 9d458e49-0325-4176-b1c8-1da11d37bf22 4DNFI823LSI8\n",
      "md5 old style or dub 5734b888-4b1c-4a81-8f63-479539fa06b6 4DNFIZQZ39L9\n",
      "md5 old style or dub d67bd814-c251-4dbb-bae8-b937077ea9ac 4DNFIZQZ39L9\n",
      "md5 old style or dub 3c5eb494-38de-472c-a596-c50dde2fd51e 4DNFIZQZ39L9\n",
      "md5 old style or dub 581e0da2-e534-4799-bcf9-155190913ff4 4DNFIZQZ39L9\n",
      "181 workflowruns from 96 files need to be deleted\n",
      "0\n",
      "0 md5 fields deleted\n",
      "0 qc metrics deleted\n",
      "0 deleted output files\n",
      "finished at 2018-11-26 16:50:01.408417\n"
     ]
    }
   ],
   "source": [
    "print(len(files), 'files in the system')\n",
    "delete_workflows = input(\"Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\")\n",
    "counter = 0\n",
    "del_md5 = 0\n",
    "del_qc = 0\n",
    "deleted_output = 0\n",
    "deleted_wfrs = []\n",
    "for a_file in files:\n",
    "    counter += 1  \n",
    "    if counter % 100 == 0:\n",
    "        print(counter, files_with_deleted_wfr)\n",
    "    raw_file = a_file\n",
    "    deleted_wf = False\n",
    "    wfr_report = []\n",
    "    wfrs = raw_file.get('workflow_run_inputs')\n",
    "    \n",
    "    # look for md5s\n",
    "    # to do add more single input runs\n",
    "    if not wfrs:\n",
    "        wfrs_url = '/search/?type=WorkflowRun&type=WorkflowRun&workflow.title=md5&input_files.value.accession='+ a_file['accession']\n",
    "        wfrs = ff_utils.search_metadata(wfrs_url , key=my_key)\n",
    "        if len(wfrs)==0:\n",
    "            print('file has no wfr', a_file['accession'])\n",
    "            \n",
    "    # Delete wfrs if file is deleted\n",
    "    if raw_file['status'] == 'deleted':\n",
    "        if delete_workflows.lower() in ['y', 'yes']:\n",
    "            # clean deleted files of md5 and qc metrics\n",
    "            for a_field in ['content_md5sum', 'md5sum']:  \n",
    "                if raw_file.get(a_field):\n",
    "                    ff_utils.delete_field(raw_file, a_field, key=my_key)\n",
    "                    del_md5 += 1\n",
    "            if raw_file.get('quality_metric'):\n",
    "                qc_uuid = raw_file['quality_metric']['uuid']\n",
    "                ff_utils.delete_field(raw_file, 'quality_metric', key=my_key)\n",
    "                # delete quality metrics object\n",
    "                patch_data = {'status': \"deleted\"}\n",
    "                ff_utils.patch_metadata(patch_data, obj_id=qc_uuid , key=my_key)\n",
    "                del_qc += 1\n",
    "                \n",
    "        # delete all workflows for deleted files\n",
    "        if not wfrs:\n",
    "            continue\n",
    "        else:\n",
    "            wfr_report = get_wfr_report(wfrs, my_key)\n",
    "            for wfr_to_del in wfr_report:\n",
    "                if wfr_to_del['status'] != 'deleted':\n",
    "                    if wfr_to_del['wfr_name'] not in workflow_names:\n",
    "                        print('Unlisted Workflow', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                    deleted_wf = True\n",
    "                    deleted_wfr_no += 1\n",
    "                    \n",
    "                    ####################################################\n",
    "                    ## TEMPORARY PIECE##################################\n",
    "                    if wfr_to_del['status'] == 'released to project':\n",
    "                        print('saved from deletion', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                        continue\n",
    "                    if wfr_to_del['status'] == 'released':\n",
    "                        print('delete released!!!!!', wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                        continue  \n",
    "                    #####################################################\n",
    "                    \n",
    "                    print(wfr_to_del['wfr_name'], 'deleted file workflow', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                    if delete_workflows.lower() in ['y', 'yes']:\n",
    "                        patch_data = {'description': \"This workflow run is deleted\", 'status': \"deleted\"}\n",
    "                        deleted_wfrs.append(wfr_to_del['wfr_uuid'])\n",
    "                        ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,key=my_key)\n",
    "                        # delete output files of the deleted workflow run\n",
    "                        if wfr_to_del['outputs']:\n",
    "                            for out_file in wfr_to_del['outputs']:\n",
    "                                deleted_output += 1\n",
    "                                ff_utils.patch_metadata({'status': \"deleted\"}, obj_id=out_file ,key=my_key)\n",
    "       \n",
    "                \n",
    "    else:\n",
    "        # get a report on all workflow_runs\n",
    "        if not wfrs:\n",
    "            continue\n",
    "        else:\n",
    "            wfr_report = get_wfr_report(wfrs, my_key)\n",
    "            # printTable(wfr_report, ['wfr_name', 'run_time', 'wfr_rev', 'run_time', 'wfr_status'])\n",
    "            # check if any unlisted wfr in report\n",
    "            my_wfr_names = [i['wfr_name'] for i in wfr_report]\n",
    "            unlisted = [x for x in my_wfr_names if x not in workflow_names]\n",
    "            # report the unlisted ones\n",
    "            #if unlisted:\n",
    "                #print('Unlisted Workflow', unlisted, 'skipped in', raw_file['accession'])\n",
    "                    \n",
    "            for wf_name,accepted_rev,accepted_run_time in workflow_details:\n",
    "                #for each type of worklow make a list of old ones, and patch status and description\n",
    "                sub_wfrs = [i for i in wfr_report if i['wfr_name'] == wf_name]\n",
    "                if sub_wfrs:\n",
    "                    active_wfr = sub_wfrs[-1]\n",
    "                    old_wfrs = sub_wfrs [:-1]\n",
    "                    # check the status of the most recent workflow\n",
    "                    if active_wfr['wfr_status'] != 'complete':\n",
    "                        if active_wfr['wfr_status'] in ['running', 'started'] and active_wfr['run_time'] < accepted_run_time:\n",
    "                            print(wf_name,'still running for', a_file['accession'])\n",
    "                        else:\n",
    "                            old_wfrs.append(active_wfr)\n",
    "                    elif active_wfr['wfr_rev'] not in accepted_rev:\n",
    "                        old_wfrs.append(active_wfr)\n",
    "                    if old_wfrs:\n",
    "                        for wfr_to_del in old_wfrs:\n",
    "                            if wfr_to_del['status'] != 'deleted':\n",
    "                                deleted_wf = True\n",
    "                                deleted_wfr_no += 1 \n",
    "                                \n",
    "                                ####################################################\n",
    "                                ## TEMPORARY PIECE\n",
    "                                if wfr_to_del['status'] == 'released to project':\n",
    "                                    print('saved from deletion',wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                    continue\n",
    "                                if wfr_to_del['status'] == 'released':\n",
    "                                    print('delete released????',wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                    continue\n",
    "                                ####################################################\n",
    "\n",
    "                                print(wfr_to_del['wfr_name'], 'old style or dub', wfr_to_del['wfr_uuid'], raw_file['accession'])\n",
    "                                \n",
    "                                if delete_workflows.lower() in ['y', 'yes']:\n",
    "                                    patch_data = {'description': \"This workflow run is deleted\", 'status': \"deleted\"}\n",
    "                                    deleted_wfrs.append(wfr_to_del['wfr_uuid'])\n",
    "                                    \n",
    "                                    ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,key=my_key)\n",
    "                                    # delete output files of the deleted workflow run\n",
    "                                    if wfr_to_del['outputs']:\n",
    "                                        for out_file in wfr_to_del['outputs']:\n",
    "                                            deleted_output += 1\n",
    "                                            ff_utils.patch_metadata({'status': \"deleted\"}, obj_id=out_file ,key=my_key)\n",
    "    if deleted_wf:\n",
    "        files_with_deleted_wfr += 1\n",
    "\n",
    "\n",
    "\n",
    "if delete_workflows.lower() in ['y', 'yes']:\n",
    "    print(str(deleted_wfr_no),\"workflowruns from\", str(files_with_deleted_wfr), \"files deleted\")\n",
    "else:\n",
    "    print(str(deleted_wfr_no),\"workflowruns from\", str(files_with_deleted_wfr), \"files need to be deleted\")\n",
    "\n",
    "print(len(deleted_wfrs))\n",
    "print(del_md5, 'md5 fields deleted')\n",
    "print(del_qc, 'qc metrics deleted')\n",
    "print(deleted_output, 'deleted output files')\n",
    "print('finished at', datetime.utcnow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing trigger and accumulating runs\n",
    "\n",
    "There are many runs where we are running out of option to utilize the exisiting tool sets\n",
    "for this cases I would like to implement a new checker, which will be used for testing \n",
    "existing frame works and also make sure that newly implemented tools are working in synch with\n",
    "them.\n",
    "\n",
    "This are the minor details that we should pay attention to while building complex tools that wrap many components\n",
    "that are also dynamic. Even a simple version menagement can become problematic when different package management tools \n",
    "are used in combination.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
