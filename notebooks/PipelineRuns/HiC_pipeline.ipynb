{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcicutils import ff_utils\n",
    "from functions.wfr import *\n",
    "from functions.wfr_settings import *\n",
    "from functions.notebook_functions import *\n",
    "\n",
    "# tibanna = Tibanna(env=env)\n",
    "my_env = 'data'\n",
    "my_auth = get_key('koray_data')\n",
    "\n",
    "# different types of exps use different steps at the last step(3).\n",
    "recipe = [\n",
    "    [['in%20situ%20Hi-C', 'dilution%20Hi-C'], 'hi-c-processing-pairs'],\n",
    "    [['micro-C',          'DNase%20Hi-C'],    'hi-c-processing-pairs-nore'],\n",
    "    [['capture%20Hi-C',   'PLAC-seq'],        'hi-c-processing-pairs-nonorm'],\n",
    "    [['CHIA-pet',         'TrAC-loop'],       'hi-c-processing-pairs-nore-nonorm'],\n",
    "    [['TCC'], 'hi-c-processing-pairs'],\n",
    "    \n",
    "]\n",
    "\n",
    "# To Do assign core 8 and more memory (\"instance_type\": \"c4.4xlarge\",) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/?experiments_in_set.experiment_type=TCC&type=ExperimentSetReplicate&limit=all&status=pre-release&status=released&status=released%20to%20project\n",
      "3 total number of sets\n",
      "0 sets completed\n",
      "0 sets skipped for small size\n",
      "3 ready for processing\n",
      "\n",
      "1 4DNESIZMF58U HindIII mouse 21\n",
      "4DNEXQAO3GNK part1 complete\n",
      "4DNEXQAO3GNK part2 complete\n",
      "4DNEXACCWMEN part1 complete\n",
      "4DNEXACCWMEN part2 complete\n",
      "part3 still running\n",
      "\n",
      "2 4DNESLUJ3INP HindIII mouse 18\n",
      "4DNEX1Y5NYNB part1 complete\n",
      "4DNEX1Y5NYNB part2 complete\n",
      "4DNEXGWOOI8I part1 complete\n",
      "4DNEXGWOOI8I part2 complete\n",
      "4DNESLUJ3INP part3 complete\n",
      "\n",
      "3 4DNESAOU4AAQ HindIII mouse 20\n",
      "4DNEXN25ESPT part1 complete\n",
      "4DNEXN25ESPT part2 complete\n",
      "4DNEXQ3PS6HH part1 complete\n",
      "4DNEXQ3PS6HH part2 complete\n",
      "4DNESAOU4AAQ is missing Part3\n",
      "1\n",
      "['4DNESLUJ3INP']\n"
     ]
    }
   ],
   "source": [
    "## TODO make sure set_url is compatible with the set_url sets\n",
    "\n",
    "#Choose the recipe element to run the pipeline on\n",
    "recipe_no = 4\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "\n",
    "#Choose the type of operations you want\n",
    "add_pc = False    #add processed files to 'other processed files\n",
    "add_tag = False   #add the completed process tag if done with all steps\n",
    "add_wfr = False   #start missing wfrs\n",
    "\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=pre-release&status=released&status=released%20to%20project'\n",
    "print(set_url)\n",
    "#set_url = '/search/?award.project=ENCODE&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "\n",
    "#set_url = '/search/?award.project=4DN&experiments_in_set.biosample.biosource.individual.organism.name=fruit-fly&experimentset_type=replicate&type=ExperimentSetReplicate'\n",
    "#print set_url\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "uncompleted_sets = [i for i in all_sets if \"HiC_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "run_sets = [i for i in uncompleted_sets if \"HiC_Pipeline_0.2.5-skipped-small-set\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "print(len(all_sets), 'total number of sets')\n",
    "print(len(all_sets)-len(uncompleted_sets), 'sets completed')\n",
    "print(len(uncompleted_sets)-len(run_sets), 'sets skipped for small size')\n",
    "print(len(run_sets), 'ready for processing')\n",
    "\n",
    "for a_set in run_sets: \n",
    "    attributions = None\n",
    "    print()\n",
    "    counter += 1\n",
    "        \n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size, lab = find_pairs(a_set, my_env)\n",
    "    # skip based on these conditions\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print(counter, a_set['accession'], organism, enzyme, 'skipping set with no chrsize/bwa index')\n",
    "        continue\n",
    "    if 'nonorm' not in step3:\n",
    "        if f_size < 4:\n",
    "            print(counter, a_set['accession'], 'skipping small file size', str(f_size))\n",
    "            continue\n",
    "    if 'nore' not in step3:\n",
    "        if not enz_ref:\n",
    "            print(counter, a_set['accession'], 'skipping not ready NZ', organism, enzyme)\n",
    "            continue\n",
    "    print(counter, a_set['accession'],enzyme, organism,f_size)\n",
    "    part3 = 'done'\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments, skip the ones without usable files\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        \n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            if not attributions:\n",
    "                attributions = get_attribution(ff_utils.get_metadata(pair[0], key = my_auth))\n",
    "            step1_result = get_wfr_out(pair[0], 'bwa-mem 0.2.5', my_auth)\n",
    " \n",
    "            # if successful\n",
    "            if step1_result['status'] == 'complete':\n",
    "                exp_bams.append(step1_result['bam'])\n",
    "                continue\n",
    "            # if still running\n",
    "            elif step1_result['status'] == 'running':\n",
    "                part1 = 'not done'\n",
    "                print('part1 still running')\n",
    "                continue\n",
    "            # if run is not successful\n",
    "            else:\n",
    "                part1 = 'not done'\n",
    "                if add_wfr:\n",
    "                    # RUN PART 1\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(step_settings('bwa-mem', organism, attributions), inp_f, name_tag, my_auth, my_env)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print(exp, 'has missing Part1 runs')\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print(exp, 'part1 complete')\n",
    "           \n",
    "        #make sure all input bams went through same last step2\n",
    "        all_step2s = []\n",
    "        for bam in exp_bams:\n",
    "            step2_result = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', my_auth)\n",
    "            all_step2s.append((step2_result['status'],step2_result.get('bam')))\n",
    "        if len(list(set(all_step2s))) != 1:\n",
    "            print('inconsistent step2 run for input bams')\n",
    "            # this run will be repeated if add_wfr\n",
    "            step2_result['status'] = 'inconsistent run'\n",
    "            \n",
    "        #check if part 2 is run already, it not start the run\n",
    "        # if successful\n",
    "        if step2_result['status'] == 'complete':\n",
    "            set_pairs.append(step2_result['pairs'])\n",
    "            if add_pc:\n",
    "                add_preliminary_processed_files(exp, [step2_result['bam'],step2_result['pairs']], my_auth)\n",
    "            print(exp, 'part2 complete')\n",
    "            continue\n",
    "        # if still running\n",
    "        elif step2_result['status'] == 'running':\n",
    "            part2 = 'not done'\n",
    "            part3 = 'not ready'\n",
    "            print(exp, 'part2 still running')\n",
    "            continue\n",
    "        # if run is not successful\n",
    "        else:\n",
    "            part2 = 'not done'\n",
    "            part3 = 'not ready'\n",
    "            print(exp, 'is missing Part2')\n",
    "            if add_wfr:\n",
    "                # RUN PART 2\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(step_settings('hi-c-processing-bam', organism, attributions), inp_f, exp, my_auth, my_env) \n",
    "\n",
    "                \n",
    "    if part3 is not 'done':\n",
    "        print('Part3 not ready')\n",
    "        continue\n",
    "    if not set_pairs:\n",
    "        print('no pairs can be produced from this set')\n",
    "        continue\n",
    "\n",
    "    #make sure all input bams went through same last step3\n",
    "    all_step3s = []\n",
    "    for a_pair in set_pairs:\n",
    "        step3_result = get_wfr_out(a_pair, step3 + \" 0.2.5\", my_auth)\n",
    "        all_step3s.append((step3_result['status'], step3_result.get('mcool')))\n",
    "    if len(list(set(all_step3s))) != 1:\n",
    "        print('inconsistent step3 run for input pairs')\n",
    "        # this run will be repeated if add_wfr\n",
    "        step3_result['status'] = 'inconsistent run'\n",
    "    #check if part 3 is run already, it not start the run\n",
    "    # if successful\n",
    "    if step3_result['status'] == 'complete':\n",
    "        completed += 1\n",
    "        completed_acc.append(a_set['accession'])\n",
    "        #add competed flag to experiment\n",
    "        if add_tag:\n",
    "            ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5\"]}, obj_id=a_set['accession'] , key=my_auth)\n",
    "        # add processed files to set\n",
    "        if add_pc:\n",
    "            add_preliminary_processed_files(a_set['accession'], \n",
    "                                            [step3_result['pairs'],\n",
    "                                             step3_result['hic'],\n",
    "                                             step3_result['mcool']], \n",
    "                                            my_auth)\n",
    "        print(a_set['accession'], 'part3 complete')\n",
    "    # if still running\n",
    "    elif step3_result['status'] == 'running':\n",
    "        print('part3 still running')\n",
    "        continue\n",
    "    # if run is not successful\n",
    "    else:\n",
    "        print(a_set['accession'], 'is missing Part3')\n",
    "        if add_wfr:\n",
    "            # RUN PART 3\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref}\n",
    "            if recipe_no in [0,2,4]:\n",
    "                inp_f['restriction_file'] = enz_ref\n",
    "            run_missing_wfr(step_settings(step3, organism, attributions), inp_f, a_set['accession'], my_auth, my_env)\n",
    "\n",
    "print(completed)\n",
    "print(completed_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3 4DNESH4UTRNL DpnII mouse 800  -  4DNEX4KRGMAQ is missing Part2 - Fails at runtaskawsem\n",
    "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:hi-c-processing-bam_4DNEX4KRGMAQ9b484528-5651-4d72-a271-a9b37a42ab05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/?experiments_in_set.experiment_type=micro-C&experiments_in_set.experiment_type=DNase%20Hi-C&type=ExperimentSetReplicate&limit=all&status=released&status=released%20to%20project\n",
      "4\n",
      "a\n",
      "4DNESIQ6IPCO\n",
      "b\n",
      "a\n",
      "4DNESVW165TO\n",
      "b\n",
      "a\n",
      "4DNES8BLXVP5\n",
      "b\n",
      "a\n",
      "4DNESLOL2OR2\n",
      "b\n",
      "4 items are ready\n"
     ]
    }
   ],
   "source": [
    "# Move files from opc to pc\n",
    "from dcicutils import ff_utils\n",
    "from functions.notebook_functions import *\n",
    "from functions.wfr import *\n",
    "\n",
    "recipe_no = 1\n",
    "exp_type, step3 = recipe[recipe_no]\n",
    "action = False\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "set_url = '/search/?'+ \\\n",
    "          '&'.join(['experiments_in_set.experiment_type='+i for i in exp_type])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "          '&status=released&status=released%20to%20project'\n",
    "\n",
    "print(set_url)\n",
    "set_url = '/search/?award.project=4DN&experimentset_type=replicate&lab.display_title=Chuck+Murry%2C+UW&status=pre-release&type=ExperimentSetReplicate'\n",
    "\n",
    "# exp\n",
    "# set_url = '/search/?'+ \\\n",
    "#           '&'.join(['experiment_type='+i for i in exp_type])+ \\\n",
    "#           '&type=Experiment&limit=all' + \\\n",
    "#           '&status=released&status=released%20to%20project'\n",
    "\n",
    "all_sets = ff_utils.search_metadata(set_url , key=my_auth)\n",
    "\n",
    "ready_sets_1 = [i for i in all_sets if \"HiC_Pipeline_0.2.5\" in i.get('completed_processes', [])]\n",
    "print(len(ready_sets_1))\n",
    "ready_sets_2 = []\n",
    "for a_set in ready_sets_1:\n",
    "    if a_set.get('other_processed_files'):\n",
    "        print('a')\n",
    "        print(a_set['accession'])\n",
    "        if move_title in [i['title'] for i in a_set['other_processed_files']]:\n",
    "            print('b')\n",
    "            if a_set.get('processed_files'):\n",
    "                print('c')\n",
    "                print('WARN' ,a_set['accession'], 'has items in processed files, skipping ')\n",
    "                continue\n",
    "            else:\n",
    "                ready_sets_2.append(a_set)\n",
    "print(len(ready_sets_2), 'items are ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 experiment sets in scope\n",
      "1 4DNESIQ6IPCO\n",
      "4DNESIQ6IPCO files will move\n",
      "4DNESIQ6IPCO moved to pc\n",
      "4DNEXXARC33I files will move\n",
      "4DNEXXARC33I moved to pc\n",
      "4DNEXQ83RPBN files will move\n",
      "4DNEXQ83RPBN moved to pc\n",
      "\n",
      "2 4DNESVW165TO\n",
      "4DNESVW165TO files will move\n",
      "4DNESVW165TO moved to pc\n",
      "4DNEX4K24I1K files will move\n",
      "4DNEX4K24I1K moved to pc\n",
      "4DNEX31BLR1Y files will move\n",
      "4DNEX31BLR1Y moved to pc\n",
      "\n",
      "3 4DNES8BLXVP5\n",
      "4DNES8BLXVP5 files will move\n",
      "4DNES8BLXVP5 moved to pc\n",
      "4DNEXGNEOZPK files will move\n",
      "4DNEXGNEOZPK moved to pc\n",
      "4DNEXX4FXLWH files will move\n",
      "4DNEXX4FXLWH moved to pc\n",
      "\n",
      "4 4DNESLOL2OR2\n",
      "4DNESLOL2OR2 files will move\n",
      "4DNESLOL2OR2 moved to pc\n",
      "4DNEXBMMAFHR files will move\n",
      "4DNEXBMMAFHR moved to pc\n",
      "4DNEX6WMRN9E files will move\n",
      "4DNEX6WMRN9E moved to pc\n",
      "\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# move other processed files to processed files field\n",
    "action = True\n",
    "def move_opc_to_pc(resp, move_title, con_key):\n",
    "    opc = resp.get('other_processed_files')\n",
    "    pc = resp.get('processed_files')\n",
    "    # if processed_files field already has values, exit\n",
    "    if pc:\n",
    "        if opc:\n",
    "            print('There are files in processed_files field, expected empty', resp['accession'])\n",
    "            return False\n",
    "        else:\n",
    "            print('it is possible that move already happened, no opc but pc', resp['accession'])\n",
    "    # see if there are other_processed_files to move\n",
    "    if opc:\n",
    "        titles = [i['title'] for i in opc]\n",
    "        if move_title in titles:\n",
    "            print(resp['accession'], 'files will move')\n",
    "            move_item = [i for i in opc if i['title'] == move_title]\n",
    "            assert len(move_item) == 1\n",
    "            assert move_item[0]['type'] == 'preliminary'\n",
    "            new_pc = move_item[0]['files']\n",
    "            new_opc = [i for i in opc if i['title'] != move_title]\n",
    "            # Time to patch\n",
    "            patch_data = {}\n",
    "            add_on = \"\"\n",
    "            #if there is something left in opc, patch it, if not delete field\n",
    "            if new_opc:\n",
    "                patch_data['other_processed_files'] = opc\n",
    "            else:\n",
    "                add_on = 'delete_fields=other_processed_files'\n",
    "            # patch with processed files\n",
    "            patch_data['processed_files'] = new_pc\n",
    "            if action:\n",
    "                ff_utils.patch_metadata(patch_data, resp['uuid'], key = con_key, add_on = add_on)\n",
    "                # update status of pc to status of set or exp\n",
    "                release_files(resp['uuid'], new_pc, con_key)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "set_w_apf = 0\n",
    "exp_w_apf = 0\n",
    "counter = 0\n",
    "move_title = 'HiC Processing Pipeline - Preliminary Files'\n",
    "\n",
    "print(len(ready_sets_2), 'experiment sets in scope')\n",
    "for a_set in ready_sets_2:\n",
    "    set_resp = ff_utils.get_metadata(a_set['uuid'],key=my_auth, add_on='frame=raw')\n",
    "    counter += 1\n",
    "    print(counter, set_resp['accession'])\n",
    "    exps = set_resp['experiments_in_set']\n",
    "    res =  move_opc_to_pc(set_resp, move_title, my_auth)\n",
    "    if res:\n",
    "        set_w_apf += 1\n",
    "        print(set_resp['accession'], 'moved to pc')\n",
    "  \n",
    "    for exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(exp, key=my_auth, add_on='frame=raw')\n",
    "        res_e =  move_opc_to_pc(exp_resp,move_title,my_auth)\n",
    "        if res_e:\n",
    "            exp_w_apf += 1\n",
    "            print(exp_resp['accession'], 'moved to pc')\n",
    "    print()\n",
    "\n",
    "print(set_w_apf)\n",
    "print(exp_w_apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
